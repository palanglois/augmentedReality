\documentclass[a4paper,10pt]{article}

\usepackage[utf8]{inputenc}
\usepackage{natbib}
\usepackage[vmargin=2cm]{geometry}

\setlength{\bibsep}{1pt}
\usepackage{graphicx}
\graphicspath{{Figures/}}

\usepackage{hyperref}
\hypersetup{
  colorlinks, linkcolor=red
}

\renewcommand{\bibfont}{\small}


%\title{Project report - Object Recognition and Computer vision}
\title{%
	\huge{Assembling LEGO set with augmented reality instructions}\\ \bigbreak
  	\Large{Project report}\\ 
  	\Large{Object Recognition and Computer vision - MVA}
}
\author{Othman Sbai, Pierre-Alain Langlois}
\date\today

\pdfinfo{%
  /Title    (Project report - Computer vision - Sbai & Langlois)
  /Author   (Othman Sbai, Pierre-Alain Langlois)
  /Creator  (Pierre-Alain Langlois, Othman Sbai)
  /Subject  (Augmented reality - tracking)
  /Keywords (augmented reality neural network ponts)
}

\begin{document}

\maketitle

\section{Introduction}
The advent of augmented reality devices such as Microsoft Hololens, Sony SmartEyeglass or Google Glass and others have made possible many interesting applications that augment the visual experience of the user with 3D holograms that are blended on his reality. Applications range from interior decoration and design, gaming but also increasing productivity in businesses by enhancing the real world and giving birth to broader imagination.

Among the applications of this new promising technology still in development, one can be interested providing instructions for people to help them accomplish tasks either with human supervision or by annotating reality. In fact, as presented in \cite{alayrac_unsupervised_2015}, we can extract from the tutorial videos available online instructions for performing many tasks such as changing car tires, assembling furniture and also performing Cardiopulmonary rescucitation. These instructions can be efficiently provided to user with a 3D augmented reality device in the form of holograms and world annotations that are much comprehensible than paper instructions. An example of this world annotation is illustrated in the following figure~\ref{AnnotatingTheWorld}.


\begin{figure}
    \centering
    \includegraphics[width=0.75\textwidth]{Annotating_world_hololens}
    \caption{Annotating the world with Microsoft Hololens}
    \label{AnnotatingTheWorld}
\end{figure}

\section{Approach of the project}
As a simplified approach to the problem providing holographic instructions as described before, we set to work on the assembly of a LEGO set using a Microsoft Hololens device to visualize the created 3D holograms and assessing the created experience. 

\subsection{Lego set description} % parts and choice ...
In coordination with other group of students working on a similar project topic, we decided to choose the LEGO set named "Blue racer" (ref 31027) shown in figure~\ref{BlueRacer}
\begin{figure}
    \centering
    \includegraphics[width=0.5\textwidth]{BlueRacer}
    \caption{Lego set chosen for this project}
    \label{BlueRacer}
\end{figure}

\section{Introduction to Hololens device}

\subsection{Working with hololens}

Microsoft Hololens is not a cheap platform to work on as it cost at least 3000\$. Thankfully, there is the possibility of working on an emulator for hololens on Visual Studio. This requires a certain setup:
\begin{itemize}
	\item Visual studio 2015 and Windows 10 Pro or Education (in order to support virtualization)
	\item Unity game engine
\end{itemize}

There are several interesting and good tutorials to start working with hololens emulator. The process of building an app for hololens requires:
\begin{itemize}
	\item First creating and setting up the scene in Unity (camera position, background...)
	\item Setting some build settings, and building the solution for visual studio
	\item Modifying the C\# scripts 
	\item Running the app on the emulator
\end{itemize}

Modifying the scene requires rebuilding the solution in Unity and reloading it in VS while modifying only the scripts requires only running the app in VS.

\subsection{About Hololens device - input/output description}

A hologram is an object made of light and sound, Hololens device renders 3D objects in precise locations of the world. It has a dynamic sensor-driven understanding of the world and updates the holograms depending on user head movement. In order to make the created holograms look realistic, the Hololens does a \emph{spatial mapping} of the surrounding environment of the user which dynamically updates mapping of surrounding objects so that holograms can live relatively to the real world 3D objects. 

HoloLens includes a world-facing camera mounted on the front of the device which will be our input for 2D object recognition and localisation (i.e the current LEGO assembly status and localisation of objects of interest). The captured frames provide RGB data as well as the location of the camera in the world, and the perspective projection of the camera. 

% this part can be removed
\subsection{Other inputs of the hololens}

Hololens provides several interesting inputs that we can use in this project. The gaze is a form of input used in holographic apps in order to target object and act on them. 


\subsection{Mapping from 2D coord in hololens RGB camera to 3D coord in Unity scene}

In order to put holograms in the correct place in the 3D scene in Unity and thus rendered in the right 3D location in user's vision, we need to map the pixel position on the RGB frame obtained from the hololens to the 3D coordinate in Unity Scene (or at least the ray)

See the section: "Pixel to Application-specified coordinate system" to find the 3D location of the hologram in the application coordinate system.

\url{https://developer.microsoft.com/en-us/windows/holographic/locatable_camera}

\subsection{Adding Holograms and placing them}
3D models of the main parts of our LEGO set are imported as prefabs in Unity assets of the project. Then, after recognizing the relevant part to be moved in the inventory, we can instantiate it and add it in the scene in a certain 3D location.

This 3D location can be inferred from the bounding box given by the 2D localisation of the part concerned. However this provides only a projected localisation, and we need to find the depth through spatial mapping.

\bibliographystyle{plain}
\bibliography{biblio}


\end{document}
