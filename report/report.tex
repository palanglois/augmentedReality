\documentclass[a4paper,10pt]{article}

\usepackage[utf8]{inputenc}
\usepackage{natbib}
\usepackage[vmargin=2cm]{geometry}

\setlength{\bibsep}{1pt}
\usepackage{graphicx}
\graphicspath{{Figures/}}

\usepackage{hyperref}
\hypersetup{
  colorlinks, linkcolor=red
}

\renewcommand{\bibfont}{\small}


%\title{Project report - Object Recognition and Computer vision}
\title{%
	\huge{Assembling LEGO set with augmented reality instructions}\\ \bigbreak
  	\Large{Project report}\\ 
  	\Large{Object Recognition and Computer vision - MVA}
}
\author{Othman Sbai, Pierre-Alain Langlois}
\date\today

\pdfinfo{%
  /Title    (Project proposal - Computer vision - Sbai & Langlois)
  /Author   (Othman Sbai, Pierre-Alain Langlois)
  /Creator  (Pierre-Alain Langlois, Othman Sbai)
  /Subject  (Augmented reality - tracking)
  /Keywords (augmented reality neural network ponts)
}

\begin{document}

\maketitle

\section{Introduction}
The advent of augmented reality devices such as Microsoft Hololens, Sony SmartEyeglass or Google Glass and others have made possible many interesting applications that augment the visual experience of the user with 3D holograms that are blended on his reality. Applications range from interior decoration and design, gaming but also increasing productivity in businesses by enhancing the real world and giving birth to broader imagination.

Among the applications of this new promising technology still in development, one can be interested providing instructions for people to help them accomplish tasks either with human supervision or by annotating reality. In fact, as presented in \cite{alayrac_unsupervised_2015}, we can extract from the tutorial videos available online instructions for performing many tasks such as changing car tires, assembling furniture and also performing Cardiopulmonary rescucitation. These instructions can be efficiently provided to user with a 3D augmented reality device in the form of holograms and world annotations that are much comprehensible than paper instructions. An example of this world annotation is illustrated in the following figure~\ref{AnnotatingTheWorld}.


\begin{figure}
    \centering
    \includegraphics[width=0.75\textwidth]{Annotating_world_hololens}
    \caption{Annotating the world with Microsoft Hololens}
    \label{AnnotatingTheWorld}
\end{figure}

\section{Approach of the project}
As a simplified approach to the problem providing holographic instructions as described before, we set to work on the assembly of a LEGO set using a Microsoft Hololens device to visualize the created 3D holograms and assessing the created experience. 

\subsection{Lego set description} % parts and choice ...
In coordination with other group of students working on a similar project topic, we decided to choose the LEGO set named "Blue racer" (ref 31027) shown in figure~\ref{BlueRacer}
\begin{figure}
    \centering
    \includegraphics[width=0.5\textwidth]{BlueRacer}
    \caption{Lego set chosen for this project}
    \label{BlueRacer}
\end{figure}

\section{Introduction to Hololens device}

\subsection{Working with hololens}

Microsoft Hololens is not a cheap platform to work on as it cost at least 3000\$. Thankfully, there is the possibility of working on an emulator for hololens on Visual Studio. This requires a certain setup:
\begin{itemize}
	\item Visual studio 2015 and Windows 10 Pro or Education (in order to support virtualization)
	\item Unity game engine
\end{itemize}

There are several interesting and good tutorials to start working with hololens emulator. The process of building an app for hololens requires:
\begin{itemize}
	\item First creating and setting up the scene in Unity (camera position, background)
	\item Setting some build settings, and building the solution for visual studio
	\item Modifying the C\# scripts 
	\item Running the app on the emulator
\end{itemize}

Modifying the scene requires rebuilding the solution in Unity and reloading it in VS while modifying only the scripts requires only running the app in VS.

\subsection{About Hololens device - input/output description}

A hologram is an object made of light and sound, Hololens device renders 3D objects in precise locations of the world. It has a dynamic sensor-driven understanding of the world and updates the holograms depending on user head movement. In order to make the created holograms look realistic, the Hololens does a \emph{spatial mapping} of the surrounding environment of the user which dynamically updates mapping of surrounding objects so that holograms can live relatively to the real world 3D objects. 

HoloLens includes a world-facing camera mounted on the front of the device which will be our input for 2D object recognition and localisation (i.e the current LEGO assembly status and localisation of objects of interest). The captured frames provide RGB data as well as the location of the camera in the world, and the perspective projection of the camera. 

% this part can be removed
\subsection{Other inputs of the hololens}

Hololens provides several interesting inputs that we can use in this project. The gaze is a form of input used in holographic apps in order to target object and act on them. 


\subsection{Mapping from 2D coord in hololens RGB camera to 3D coord in Unity scene}

In order to put holograms in the correct place in the 3D scene in Unity and thus rendered in the right 3D location in user's vision, we need to map the pixel position on the RGB frame obtained from the hololens to the 3D coordinate in Unity Scene (or at least the ray)

See the section: "Pixel to Application-specified coordinate system" to find the 3D location of the hologram in the application coordinate system.

\url{https://developer.microsoft.com/en-us/windows/holographic/locatable_camera}
\newpage

We have chosen the topic : \emph{A.3 Instructions for assembling simple lego objects}.
\smallbreak
The advent of augmented reality tools such as Microsoft Hololens have made possible many interesting 
applications that augment the visual experience of the user providing relevant informations and 
distractions. Across the web, one can find lots of tutorial videos for performing a certain task be it 
assemble a furniture, prepare a meal, change tire in addition to DIY videos. These explanations can 
really be enhanced through augmented reality technology by overlaying instructions in the view of Hololens 
for example in order to adapt the tutorial to the real world’s configuration. 
\smallbreak

We propose to tackle the problem of providing instructions for assembling simple LEGO set. This simple 
game-related problem is a good start in manipulating and recognizing 3D objects from a head-mounted camera. 
Our goal is to create an assistant that is able to recognize the state of the LEGO mounting problem and 
suggest the next step by blending virtual movement on the reality perceived by the player thanks to 
Hololens.

\smallbreak

We will first implement a system that allows to recognize and locate the pieces in the frame in real time~\cite{redmon_you_2015}. 
This system will provide simple informations to help the user assembling the pieces.

If the system works well enough, we will try to add the pose estimation in the process in order to give 
more precise informations about the pieces orientation~\cite{wohlhart_learning_2015}.

\smallbreak
Some researchers already worked on the problem of LEGO brick identification and retrieval in realtime from 
2D images\cite{botha_realtime_2009}. In our case, we will generate data directly from the hololens (both 
RGB and geometrical data), since we have only a few lego pieces to recognize. If needed, we will also use 
data augmentation techniques. 
 
\section{Plan of work}

\begin{itemize}
 \item GOAL: Implement an interactive assistant that helps solving/assembling a LEGO set. Providing relevant statistics to evaluate the performance of the method.
 \item We assume the knowledge of the set of sequences required for the assembly, this can be either 
 supplied by LEGO from the manual, or can be deduced from tutorial videos, as was done in the paper 
 \cite{alayrac_unsupervised_2015}.
 \item From a head mounted camera, recognize LEGO part to be moved and its destination and display a 
 hint of the movement overlaid on the hololens.
 \item If the previous work is good enough, we will try to add support for pose estimation and more 
 advanced instructions.

\end{itemize}


\section{Operational organization}

\subsection{Group members}

\begin{itemize}
 \item Othman Sbai (MVA \& École des Ponts ParisTech)
 \item Pierre-Alain Langlois (MVA \& École des Ponts ParisTech)
\end{itemize}


\subsection{Plans for work sharing}

%Object detection & pose estimation
Pierre-Alain will be focused on the work regarding the object detection (including segmentation) and the 
pose estimation task.
%Tracking & implementation on Hololens
Othman will be focused on the tracking constraints, and the implementation and experiments on the hololens 
device. Both of us will also perform testing on each other implementations in order to make the produced 
code more robust.


\bibliographystyle{plain}
\bibliography{biblio}


\end{document}
